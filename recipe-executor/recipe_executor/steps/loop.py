# This file was generated by Codebase-Generator, do not edit directly
"""
LoopStep: iterate over a collection, execute substeps for each item with optional concurrency.
"""
import asyncio
import logging
from typing import Any, Dict, List, Optional, Tuple, Union

from recipe_executor.protocols import ContextProtocol, ExecutorProtocol
from recipe_executor.steps.base import BaseStep, StepConfig
from recipe_executor.utils.templates import render_template

__all__ = ["LoopStep", "LoopStepConfig"]


class LoopStepConfig(StepConfig):
    """
    Configuration for LoopStep.

    Fields:
        items: Union[str, List[Any], Dict[Any, Any]]
        item_key: str
        max_concurrency: int = 1
        delay: float = 0.0
        substeps: List[Dict[str, Any]]
        result_key: str
        fail_fast: bool = True
    """

    items: Union[str, List[Any], Dict[Any, Any]]
    item_key: str
    max_concurrency: int = 1
    delay: float = 0.0
    substeps: List[Dict[str, Any]]
    result_key: str
    fail_fast: bool = True


class LoopStep(BaseStep[LoopStepConfig]):
    """
    LoopStep: iterate over a collection and execute configured substeps for each item.
    Supports async parallelism, staggered delays, and fail-fast behavior.
    """

    def __init__(self, logger: logging.Logger, config: Dict[str, Any]) -> None:
        # Validate configuration
        validated = LoopStepConfig.model_validate(config)
        super().__init__(logger, validated)

    async def execute(self, context: ContextProtocol) -> None:
        # Avoid circular import
        from recipe_executor.executor import Executor  # concrete class

        cfg = self.config
        # Resolve items definition: render if string
        items_def = cfg.items
        if isinstance(items_def, str):
            template = render_template(items_def, context)
            items_obj: Any = _resolve_path(template, context)
        else:
            items_obj = items_def

        # Validate resolved collection
        if items_obj is None:
            raise ValueError(f"LoopStep: Items '{items_def}' not found in context.")
        if not isinstance(items_obj, (list, dict)):
            raise ValueError(
                f"LoopStep: Items must be a list or dict, got {type(items_obj).__name__}."
            )

        # Flatten to list of (key, value)
        items_list: List[Tuple[Any, Any]] = (
            list(enumerate(items_obj)) if isinstance(items_obj, list) else list(items_obj.items())
        )
        total = len(items_list)
        max_conc = cfg.max_concurrency
        self.logger.info(
            f"LoopStep: Processing {total} items with max_concurrency={max_conc}."
        )

        # Handle empty
        if total == 0:
            empty_res = [] if isinstance(items_obj, list) else {}
            context[cfg.result_key] = empty_res
            self.logger.info("LoopStep: No items to process.")
            return

        # Prepare result containers
        results: Union[List[Any], Dict[Any, Any]] = [] if isinstance(items_obj, list) else {}
        errors: Union[List[Dict[str, Any]], Dict[Any, Dict[str, Any]]] = (
            [] if isinstance(items_obj, list) else {}
        )

        # Concurrency semaphore (None means unlimited)
        semaphore: Optional[asyncio.Semaphore] = None
        if max_conc > 0:
            semaphore = asyncio.Semaphore(max_conc)

        # Executor instance
        executor: ExecutorProtocol = Executor(self.logger)
        plan: Dict[str, Any] = {"steps": cfg.substeps}

        fail_fast_triggered = False
        completed = 0
        tasks: List[asyncio.Task[Tuple[Any, Any, Optional[str]]]] = []

        async def process_item(key: Any, value: Any) -> Tuple[Any, Any, Optional[str]]:
            # Clone context for isolation
            item_ctx = context.clone()
            item_ctx[cfg.item_key] = value
            if isinstance(items_obj, list):
                item_ctx["__index"] = key  # type: ignore
            else:
                item_ctx["__key"] = key  # type: ignore

            try:
                self.logger.debug(f"LoopStep: Starting item {key}.")
                await executor.execute(plan, item_ctx)
                out = item_ctx.get(cfg.item_key, value)
                self.logger.debug(f"LoopStep: Finished item {key}.")
                return key, out, None
            except Exception as exc:
                msg = str(exc)
                self.logger.error(f"LoopStep: Error on item {key}: {msg}")
                return key, None, msg

        async def run_sequential() -> None:
            nonlocal fail_fast_triggered, completed
            for key, val in items_list:
                if fail_fast_triggered:
                    break
                key_i, out, err = await process_item(key, val)
                if err:
                    if isinstance(errors, list):
                        errors.append({"index": key_i, "error": err})
                    else:
                        errors[key_i] = {"error": err}  # type: ignore
                    if cfg.fail_fast:
                        fail_fast_triggered = True
                        break
                else:
                    if isinstance(results, list):
                        results.append(out)
                    else:
                        results[key_i] = out  # type: ignore
                    completed += 1

        async def run_parallel() -> None:
            nonlocal fail_fast_triggered, completed

            async def schedule_one(k: Any, v: Any) -> Tuple[Any, Any, Optional[str]]:
                if semaphore:
                    async with semaphore:
                        return await process_item(k, v)
                return await process_item(k, v)

            # Launch tasks
            for idx, (k, v) in enumerate(items_list):
                if fail_fast_triggered:
                    break
                tasks.append(asyncio.create_task(schedule_one(k, v)))
                if cfg.delay and idx < total - 1:
                    await asyncio.sleep(cfg.delay)

            # Collect
            for task in asyncio.as_completed(tasks):  # type: ignore
                if fail_fast_triggered:
                    break
                try:
                    key_i, out, err = await task
                    if err:
                        if isinstance(errors, list):
                            errors.append({"index": key_i, "error": err})
                        else:
                            errors[key_i] = {"error": err}  # type: ignore
                        if cfg.fail_fast:
                            fail_fast_triggered = True
                            continue
                    else:
                        if isinstance(results, list):
                            results.append(out)
                        else:
                            results[key_i] = out  # type: ignore
                        completed += 1
                except Exception as unexpected:
                    self.logger.error(f"LoopStep: Unexpected error: {unexpected}")
                    if cfg.fail_fast:
                        fail_fast_triggered = True
                        break

        # Execute according to concurrency
        if max_conc <= 1:
            await run_sequential()
        else:
            await run_parallel()

        # Store outputs in parent context
        context[cfg.result_key] = results
        if errors:
            context[f"{cfg.result_key}__errors"] = errors

        err_count = len(errors) if isinstance(errors, (list, dict)) else 0
        self.logger.info(
            f"LoopStep: Completed {completed}/{total} items. Errors: {err_count}."
        )



def _resolve_path(path: str, context: ContextProtocol) -> Any:
    """
    Resolve a dot-notated path against the context or nested dicts.
    """
    current: Any = context
    for seg in path.split('.'):
        if isinstance(current, ContextProtocol):
            current = current.get(seg)
        elif isinstance(current, dict):
            current = current.get(seg)
        else:
            return None
        if current is None:
            return None
    return current
