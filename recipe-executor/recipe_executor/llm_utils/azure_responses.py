# This file was generated by Codebase-Generator, do not edit directly
"""
Azure Responses component for Recipe Executor
Provides PydanticAI wrapper for Azure OpenAI Responses API models.
Handles authentication (API key or Managed Identity) and model initialization.
"""

import os
import logging
from typing import Optional

from azure.identity import DefaultAzureCredential, get_bearer_token_provider
from openai import AsyncAzureOpenAI
from pydantic_ai.models.openai import OpenAIResponsesModel
from pydantic_ai.providers.openai import OpenAIProvider

logger = logging.getLogger(__name__)


def _mask_key(key: str) -> str:
    """Mask all but first and last character of a secret key."""
    if not key:
        return ""
    if len(key) <= 2:
        return "*" * len(key)
    return f"{key[0]}{'*' * (len(key) - 2)}{key[-1]}"


def create_azure_responses_model(
    model_name: str,
    deployment_name: Optional[str] = None,
) -> OpenAIResponsesModel:
    """
    Create a configured OpenAIResponsesModel for Azure OpenAI.

    Args:
        model_name: Name of the underlying model or alias.
        deployment_name: Optional override for the Azure deployment name.

    Returns:
        Configured OpenAIResponsesModel using Azure authentication.

    Raises:
        ValueError: If required environment variables are missing or invalid.
    """
    # Determine authentication method
    use_managed_identity = os.getenv("AZURE_USE_MANAGED_IDENTITY", "false").strip().lower() in ("true", "1", "yes")

    # Required endpoint configuration
    base_url = os.getenv("AZURE_OPENAI_BASE_URL")
    if not base_url:
        raise ValueError("AZURE_OPENAI_BASE_URL environment variable is required for Azure OpenAI endpoint")

    # API version
    api_version = os.getenv("AZURE_OPENAI_API_VERSION", "2025-03-01-preview").strip()

    # Optional API key
    api_key = os.getenv("AZURE_OPENAI_API_KEY")

    # Determine deployment name
    env_deployment = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME")
    final_deployment = deployment_name or env_deployment or model_name

    # Debug log loaded configuration (mask secrets)
    masked_key = _mask_key(api_key) if api_key else None
    logger.debug(
        "Azure Responses config: use_managed_identity=%s, base_url=%s, api_version=%s, deployment_name=%s, api_key=%s",
        use_managed_identity,
        base_url,
        api_version,
        final_deployment,
        masked_key,
    )

    try:
        # Initialize Azure OpenAI client
        if use_managed_identity:
            # Use Azure AD Managed Identity
            client_id = os.getenv("AZURE_CLIENT_ID")
            # DefaultAzureCredential picks up client ID from env if provided,
            # but we pass explicitly if present
            if client_id:
                credential = DefaultAzureCredential(managed_identity_client_id=client_id)
            else:
                credential = DefaultAzureCredential()
            # Scope for Azure Cognitive Services
            scope = "https://cognitiveservices.azure.com/.default"
            token_provider = get_bearer_token_provider(credential, scope)
            azure_client = AsyncAzureOpenAI(
                azure_endpoint=base_url,
                api_version=api_version,
                azure_ad_token_provider=token_provider,
            )
            auth_method = "managed_identity"
        else:
            # API key authentication
            if not api_key:
                raise ValueError("AZURE_OPENAI_API_KEY environment variable is required for API key authentication")
            azure_client = AsyncAzureOpenAI(
                azure_endpoint=base_url,
                api_version=api_version,
                api_key=api_key,
            )
            auth_method = "api_key"

        logger.info(
            "Authenticated Azure OpenAI client using %s for deployment %s",
            auth_method,
            final_deployment,
        )

        # Create PydanticAI Responses model
        provider = OpenAIProvider(openai_client=azure_client)
        model = OpenAIResponsesModel(final_deployment, provider=provider)
        logger.info("Created Azure Responses model '%s'", final_deployment)
        return model

    except Exception as err:
        logger.debug("Failed to create Azure Responses model '%s': %s", final_deployment, err, exc_info=True)
        raise
